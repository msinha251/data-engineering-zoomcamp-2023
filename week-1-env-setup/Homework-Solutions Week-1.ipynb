{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc00cea",
   "metadata": {},
   "source": [
    "###  Question 1. Knowing docker tags\n",
    "Run the command to get information on Docker\n",
    "\n",
    "docker --help\n",
    "\n",
    "Now run the command to get help on the \"docker build\" command\n",
    "\n",
    "Which tag has the following text? - Write the image ID to the file\n",
    "\n",
    "--iidfile string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d58bf",
   "metadata": {},
   "source": [
    "### Question 2. Understanding docker first run\n",
    "Run docker with the python:3.9 image in an interactive mode and the entrypoint of bash. Now check the python modules that are installed ( use pip list). How many python packages/modules are installed?\n",
    "\n",
    "\n",
    "3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aad337",
   "metadata": {},
   "source": [
    "### Prepare Postgres\n",
    "\n",
    "Run Postgres and load data as shown in the videos We'll use the green taxi trips from January 2019:\n",
    "\n",
    "wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
    "\n",
    "Download this data and put it into Postgres (with jupyter notebooks or with a pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4592a2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-27 11:05:05--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/d3904232-1a2b-431b-803d-0ee802cd14fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230127T110506Z&X-Amz-Expires=300&X-Amz-Signature=94fa2b01f2279617488c42f8c634d17b86eaae5860ab264508db9654e6b444a5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-01.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-01-27 11:05:06--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/d3904232-1a2b-431b-803d-0ee802cd14fc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230127T110506Z&X-Amz-Expires=300&X-Amz-Signature=94fa2b01f2279617488c42f8c634d17b86eaae5860ab264508db9654e6b444a5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-01.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11099245 (11M) [application/octet-stream]\n",
      "Saving to: ‘green_tripdata_2019-01.csv.gz’\n",
      "\n",
      "green_tripdata_2019 100%[===================>]  10.58M  16.3MB/s    in 0.6s    \n",
      "\n",
      "2023-01-27 11:05:07 (16.3 MB/s) - ‘green_tripdata_2019-01.csv.gz’ saved [11099245/11099245]\n",
      "\n",
      "--2023-01-27 11:05:08--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.161.64, 52.217.143.32, 54.231.224.16, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.161.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-01-27 11:05:08 (113 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-01.csv.gz\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83e52c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630918, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('green_tripdata_2019-01.csv.gz').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45bbb5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 20)\n",
      "inserted another chunk, took 9.522 second\n",
      "inserted another chunk, took 9.502 second\n",
      "inserted another chunk, took 9.526 second\n",
      "inserted another chunk, took 9.483 second\n",
      "inserted another chunk, took 9.642 second\n",
      "inserted another chunk, took 3.000 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8921/325345183.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpep_pickup_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpep_pickup_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpep_dropoff_datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lpep_dropoff_datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1281\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## DATA INSERTION ##\n",
    "\n",
    "import pandas as pd\n",
    "# create engine\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()\n",
    "\n",
    "# create iterator to read the data in chunks\n",
    "chunksize = 100000\n",
    "df_iter = pd.read_csv('green_tripdata_2019-01.csv.gz', chunksize=chunksize, iterator=True, compression='gzip')\n",
    "df = next(df_iter)\n",
    "\n",
    "# conver tpep_pickup_datetime and tpep_dropoff_datetime to datetime\n",
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "# create table\n",
    "df.head(0).to_sql('green_taxi_trips', con=engine, if_exists='replace')\n",
    "df.to_sql('green_taxi_trips', con=engine, if_exists='append')\n",
    "\n",
    "# insert data into table\n",
    "from time import time\n",
    "\n",
    "while True: \n",
    "    t_start = time()\n",
    "    df = next(df_iter)\n",
    "    df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "    df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "    df.to_sql(name='green_taxi_trips', con=engine, if_exists='append')\n",
    "    t_end = time()\n",
    "    print('inserted another chunk, took %.3f second' % (t_end - t_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58de80d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ZONE TABLE INSERTION ##\n",
    "\n",
    "import pandas as pd\n",
    "# Read the data into a pandas dataframe\n",
    "zones = pd.read_csv('taxi+_zone_lookup.csv')\n",
    "\n",
    "# create taxi_zones table\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "zones.to_sql('taxi_zones', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a500402",
   "metadata": {},
   "source": [
    "### Question 3. Count records\n",
    "How many taxi trips were totally made on January 15?\n",
    "\n",
    "Tip: started and finished on 2019-01-15.\n",
    "\n",
    "Remember that lpep_pickup_datetime and lpep_dropoff_datetime columns are in the format timestamp (date and hour+min+sec) and not in date.\n",
    "\n",
    "```\n",
    "SELECT count(*)\n",
    "FROM green_taxi_trips\n",
    "WHERE CAST(lpep_pickup_datetime as date) >= '2019-01-15' AND CAST(lpep_dropoff_datetime as date) < '2019-01-16'\n",
    "```\n",
    "\n",
    "20530\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e50d1",
   "metadata": {},
   "source": [
    "### Question 4. Largest trip for each day\n",
    "Which was the day with the largest trip distance Use the pick up time for your calculations.\n",
    "\n",
    "\n",
    "```\n",
    "SELECT lpep_pickup_datetime\n",
    "FROM green_taxi_trips\n",
    "WHERE trip_distance = (SELECT max(trip_distance) as max_trip_distance FROM green_taxi_trips)\n",
    "\n",
    "```\n",
    "\n",
    "2019-01-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1991ab1",
   "metadata": {},
   "source": [
    "### Question 5. The number of passengers\n",
    "In 2019-01-01 how many trips had 2 and 3 passengers?\n",
    "\n",
    "```\n",
    "SELECT passenger_count, COUNT(passenger_count)\n",
    "FROM green_taxi_trips\n",
    "WHERE (passenger_count = 3 or passenger_count = 2) AND DATE(lpep_pickup_datetime) = '2019-01-01'\n",
    "group by passenger_count\n",
    "```\n",
    "\n",
    "2: 1282 ; 3: 254\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08c5b3",
   "metadata": {},
   "source": [
    "### Question 6. Largest tip\n",
    "For the passengers picked up in the Astoria Zone which was the drop off zone that had the largest tip? We want the name of the zone, not the id.\n",
    "\n",
    "Note: it's not a typo, it's tip , not trip\n",
    "\n",
    "```\n",
    "SELECT \n",
    "CONCAT(pul.\"Borough\", ' / ', pul.\"Zone\") as PickLocation,\n",
    "CONCAT(dol.\"Borough\", ' / ', dol.\"Zone\") as DropLocation,\n",
    "tip_amount\n",
    "FROM \n",
    "green_taxi_trips as gt,\n",
    "taxi_zones as pul,\n",
    "taxi_zones as dol\n",
    "WHERE gt.\"PULocationID\" = pul.\"LocationID\" AND gt.\"DOLocationID\" = dol.\"LocationID\" AND pul.\"Zone\" = 'Astoria'\n",
    "ORDER BY tip_amount DESC\n",
    "```\n",
    "\n",
    "\n",
    "Long Island City/Queens Plaza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5aad44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
